{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14f1400-bfbb-4f5a-82a7-1426a37e10f1",
   "metadata": {},
   "source": [
    "# Behind the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc06fdef-05b2-40de-8267-d9b7144ce41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998001456260681},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997509121894836}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "raw_inputs= [\"I've finally made it!\", \"Why is this not working!\"]\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(raw_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0087a7dc-27c2-4562-a9be-3121a785d446",
   "metadata": {},
   "source": [
    "## Preprocessing with a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c1dd18-280d-47f8-8c28-1f0b7f355145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f71f4a34-38f9-4a51-b95c-b3f49eeb8604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 1005, 2310, 2633, 2081, 2009,  999,  102],\n",
      "        [ 101, 2339, 2003, 2023, 2025, 2551,  999,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d695d-4e29-4d8b-8fdd-835454414816",
   "metadata": {},
   "source": [
    "## Going through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf54c54d-7a91-4bf2-974e-d7e235f49b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47f441-f63c-45ea-8bcc-439be95b82d1",
   "metadata": {},
   "source": [
    "### A high-dimensional vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afc893f5-3044-4ff4-9905-8b062297c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a91f95-9cdd-4514-bf1c-d7074a01c65c",
   "metadata": {},
   "source": [
    "### Model heads: Making sense out of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8c719da-969b-4ca0-9505-304536d56810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbe3881a-ba7a-409e-b7ad-18909875606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313556e4-0a51-4e02-ab3b-43b4a18e7124",
   "metadata": {},
   "source": [
    "## Postprocessing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cd3442f-3664-4f83-ab7c-b09592c8b02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1149,  4.4030],\n",
      "        [ 4.6786, -3.6188]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff11f30f-d2b8-488e-9815-78d99b3bb812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9983e-04, 9.9980e-01],\n",
      "        [9.9975e-01, 2.4909e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "838129bf-2e0b-40bf-8101-ad52822ab0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f3fca-a04a-4a47-a3b8-55269e8d2851",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d01b1c-c558-4fed-a720-07492aa4e56e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29ec8f61-1365-4abc-af42-bf494d3c8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "config = BertConfig()\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "249b854f-5be8-4275-9155-0ca5dd8686e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.21.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70157955-9507-4405-b02f-76a97a3c49a2",
   "metadata": {},
   "source": [
    "### Different loading methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ee40b28-c886-4343-831e-dc8aee66f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random initialization\n",
    "from transformers import BertConfig, BertModel\n",
    "config = BertConfig()\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31305751-2a7c-4a74-8563-3cc205317e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcba40cb5b3e4957ad3063a0fb738f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f23aa76073542b2b19ce3794659eacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# initialize from pretrained\n",
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35282f-0b06-44e7-bb9d-7b2e9c699087",
   "metadata": {},
   "source": [
    "### Saving methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3c2c59f-fff4-4985-8685-b6f0ae56054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "012a1133-b8b2-4358-92d1-8465896d071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json  pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls pretrained/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14548515-086e-4695-93ef-d8d67cadceb3",
   "metadata": {},
   "source": [
    "## Using a Transformer model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6d8c2ed-f974-4f54-ac69-8936691f6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"Hello!\", \"Cool!\", \"Nice!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30d6bfc9-6b51-401c-827a-fbf69d2a134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a921f02e86043139ffd7b22a2861e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478f90bb0bfe4380a980dc4f21f28349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a47bfb67124647be528f4b10178ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2560555-2f0c-4e74-aae7-63c22766fe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 8667, 106, 102], [101, 13297, 106, 102], [101, 8835, 106, 102]], 'token_type_ids': [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sequences , padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20be43bd-38ba-4707-a14e-db2f3e0e75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1f30d47-10de-435f-997f-308102fac8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_inputs = torch.tensor(encoded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f8445-29b6-4436-99d5-28df5ef8369b",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5062ed-5aed-46a0-84ca-d6378a58b3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
