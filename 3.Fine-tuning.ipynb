{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1caf28-c3ea-4185-a049-a81505f6007a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4aec7-70d0-4507-8ba4-4471d6ba7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AdamW,AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769c8d1-88f8-4480-a2d8-50f903a7760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\",\n",
    "]\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "batch[\"labels\"] = torch.tensor([1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae8847-293f-42b4-8cee-43260f01dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters())\n",
    "loss = model(**batch).loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492ca73-5586-4f42-a8bf-3c7c6a96311b",
   "metadata": {},
   "source": [
    "## Loading a dataset from the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54110665-024c-4933-a00a-eb503edbce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee024d-7e8a-4427-add5-d2f7bf9f99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653d5f4-c72a-4fe5-9a1e-fd2e9ac64de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a2d4d-81f6-457a-beba-65fa6e6f1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87330f5-ef13-4057-b207-52f2271f707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset[87]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8106937-4531-4934-a2ea-65f330273866",
   "metadata": {},
   "source": [
    "## Preprocessing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7d964-9d0d-46a7-aee8-87ed4cc9ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddeb21-92dd-4cf8-b7c4-35e6d129aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(raw_train_dataset[14]['sentence1'], raw_train_dataset[14]['sentence2'])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62065b69-df26-4a0f-8cf5-b96fa4e47dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1bd6b-eaa5-4076-a5a2-78ce257f55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803c3a5-0015-441c-9668-f4e90e21c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07b3b3-db38-417c-8f6f-ed32e803f489",
   "metadata": {},
   "source": [
    "## Dynamic padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c293ac-ea33-4ee8-bcc2-757348eeb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf461f0-7fbd-4de1-acaa-d4e0373c6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tokenized_datasets[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327639ab-bbc0-4029-931a-29ec6d498a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3fcba-13df-40e0-8cca-cb320c717589",
   "metadata": {},
   "source": [
    "## SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b74014-7159-4ab8-b235-f86c7c541c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_datasets = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabcee6d-e015-482c-b4a6-8e14c565cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10405e49-b86c-40b9-91d1-c211544e10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sst2_function(example):\n",
    "    return tokenizer(example[\"sentence\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42616604-d9c8-42a8-a449-19cf7785f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sst2_datasets = sst2_datasets.map(tokenize_sst2_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c82e6-f6df-487e-875a-c9dd303a09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_samples = tokenized_sst2_datasets[\"train\"][:8]\n",
    "sst2_samples = {k: v for k, v in sst2_samples.items() if k not in [\"idx\", \"sentence\"]}\n",
    "[len(x) for x in sst2_samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a13dd-0469-4d0b-90f4-52fbfb296ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_batch = data_collator(sst2_samples)\n",
    "{k: v.shape for k, v in sst2_batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f38cb-259a-4222-928d-8a476f655191",
   "metadata": {},
   "source": [
    "# Fine-tuning a model with the Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb068b5-628b-46ee-995b-8a999c7b7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b022e1-81fd-4291-9b11-da4330f432eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96852c-5e3f-4f67-92f2-a97bc6fb9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13161a95-9a81-4293-8886-c4bd72d55bc1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b46f97-3133-43ac-bbbd-0b47b11a11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4304fe-7056-4d80-bb7b-ced8885b9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955f7a6-8568-47b0-afe8-ccafacd5d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51eb9df-96ac-451a-bf32-db561529a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342aff9-8bc0-4982-b482-922766318809",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214f6d0-b873-4b9d-8683-ce4cc36dabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e585cd-c392-406b-ba4b-9161b8cbfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c17f9d-e7c5-4d11-9f10-4be2949fb2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a2424-168c-401e-9be9-7359dd7c3c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4dd08-2e19-4344-9a9c-4dff375ef051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31082a1e-bf70-4bb8-8a85-ddc59a6499f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f0269-8c6d-42b8-a5e9-16de72eda0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e36b21-60e7-4269-825e-31f805d5bc08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb738f26-d561-45d3-83b3-aefc6cc95d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "sst2_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6e47d-5e8b-4640-890b-05d0a8057e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sst2(example):\n",
    "    return tokenizer(example[\"sentence\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e5b79-78c1-4988-87d7-f8f252a746f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sst2_datasets = sst2_datasets.map(tokenize_sst2, batched=True)\n",
    "tokenized_sst2_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50981f3e-acba-4933-a037-702e8a67baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_sst2(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"sst2\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94416f50-099c-4abe-b6ee-74250676afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"test-trainer-sst2\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_sst2_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_sst2_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_sst2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d06b25b-ec9c-4871-9af4-aebe4ba666f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60f1fd-f352-4ff9-854a-0fb3c5f1ca0f",
   "metadata": {},
   "source": [
    "# A full training with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5250c-212a-43c0-939e-5280d4638659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45adad-9378-434f-be34-3c47d21301d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0e5cc-adb3-42f1-9345-191989269936",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55aad1-8ce3-4f08-aff5-047005f01679",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246c67e-cf4e-4203-b922-c7d8cee08b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post=process tokenized datasets\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0d167-4fd2-4748-bbf3-dc166db61064",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6977a2-14a7-477e-8bec-71c2e623ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b4efc-10f3-4cb6-ba54-1bbb25896173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb936c-6d1c-4425-a4be-4d4f0097f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataprocessing\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k:v.shape for k,v in batch.items()}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22bc00-14ab-4cea-8b65-772bc07988b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597784a-634a-47c8-8d99-12fb5cb2a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c19586-293c-4014-b65c-33bc676a3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846ebc8-9113-41d8-8deb-b22dea502b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "num_training_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17dde14-8517-48f3-942b-9d3ee64a23b0",
   "metadata": {},
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a09f58-8a4a-4e79-982e-92e0e02839d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95f478-fc6a-4704-935f-bdb15e893654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc2261-8187-437a-8789-5a55e5497e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707748d-636c-408b-92a5-8a7b075847c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08278a84-90fa-4d0e-aa63-01b1c194fd56",
   "metadata": {},
   "source": [
    "## The evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a34147f-fe73-4361-a2d4-0ecee32c7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec23a49-49f3-4b71-81bf-2f0e729141b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k:v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e1610-9a0d-470b-8293-070f0eeb09e4",
   "metadata": {},
   "source": [
    "## SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23872ebc-1ee3-4d5a-9741-095b20b48bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/sst2 (download: 7.09 MiB, generated: 4.81 MiB, post-processed: Unknown size, total: 11.90 MiB) to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e7472eb3d04d87ba9c9df94cb04c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0ac6a6d86842f88b3d67ca60589c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sst2_dataset = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "259bf009-b32b-4d40-940c-efa3b3882ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sst2(example):\n",
    "    return tokenizer(example[\"sentence\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01365289-22e5-4f32-a5f0-2357aa6ce91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c844a86c284e44ad96fa98acb8b8fd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe2fb80d5594ad3a99c0297ab69643a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d87b1c90fd44d5b4e8addb07be6b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_sst2_dataset = sst2_dataset.map(tokenize_sst2, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "434935b2-ac4f-4ec3-88ab-5383afc378c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sst2_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a819438f-c508-41fb-99af-383d1ce4c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sst2_dataset = tokenized_sst2_dataset.remove_columns([\"sentence\", \"idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15f7b8da-4d6d-4621-848b-b5150bc7df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sst2_dataset = tokenized_sst2_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51e0ea6e-4224-46a4-b893-23ebdff07901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sst2_dataset.set_format(\"torch\")\n",
    "tokenized_sst2_dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e28f926c-1c6b-4dad-bfd0-95e767e78f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_sst2_dataloader = DataLoader(\n",
    "    tokenized_sst2_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_sst2_dataloader = DataLoader(\n",
    "    tokenized_sst2_dataset[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4c41ea4-687d-4f7d-8058-51ea34e4bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_sst2 = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "031fc372-0d3f-4841-a581-5e8300b22527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([8]),\n",
       " 'input_ids': torch.Size([8, 34]),\n",
       " 'token_type_ids': torch.Size([8, 34]),\n",
       " 'attention_mask': torch.Size([8, 34])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_sst2_dataloader:\n",
    "    break\n",
    "    \n",
    "{k:v.shape for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "728a5cd3-ffd3-4070-b49b-c21491ff8fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6060, grad_fn=<NllLossBackward0>) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "outputs = model_sst2(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2b7eee4-87e5-492d-af56-4f7b07df2841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25257"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer_sst2 = AdamW(model_sst2.parameters(), lr=5e-5)\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps_sst2 = num_epochs * len(train_sst2_dataloader)\n",
    "lr_scheduler_sst2 = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps_sst2,\n",
    ")\n",
    "num_training_steps_sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74160cc2-3e48-44c0-8b77-cdc98ad6e874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_sst2.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2578df1f-c13d-46e1-80fa-db8dced8210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d788e408fa3b490cbd4d7c89a905f0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "progress_bar_sst2 = tqdm(range(num_training_steps_sst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24e1acc3-56bd-4d02-b69f-3c226c495ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in train_sst2_dataloader:\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        outputs = model_sst2(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer_sst2.step()\n",
    "        lr_scheduler_sst2.step()\n",
    "        optimizer_sst2.zero_grad()\n",
    "        progress_bar_sst2.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ebb71e2-4342-4bd3-aa23-dc9190d8fff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8727064220183486}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "metric_sst2 = evaluate.load(\"glue\", \"sst2\")\n",
    "model_sst2.eval()\n",
    "for batch in eval_sst2_dataloader:\n",
    "    batch = {k:v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_sst2(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric_sst2.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric_sst2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f13f74-c6c6-42d8-9841-90c5702c94c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
